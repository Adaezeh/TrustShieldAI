{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TrustShieldAI: Real-Time Fraud Detection Project\n",
        "\n",
        "This notebook contains the implementation of a realistic financial transaction simulation and an unsupervised fraud detection system using Isolation Forest. The goal of this project is to generate a synthetic transaction dataset that captures both normal and fraudulent behaviors, and then detect anomalies automatically.\n",
        "\n",
        "## Project Overview\n",
        "- Simulate realistic transactions for users, POS agents, and mobile money agents across all Nigerian states.\n",
        "- Incorporate geolocation, IP address, device fingerprints, and temporal features to enhance realism.\n",
        "- Model multiple fraud scenarios, including:\n",
        "  - Burst/velocity attacks\n",
        "  - Cross-state POS-card fraud\n",
        "  - Same-state POS-card fraud at distant locations\n",
        "- Perform exploratory data analysis to understand feature distributions and trends.\n",
        "- Preprocess and encode features for unsupervised anomaly detection.\n",
        "- Train and evaluate an Isolation Forest model to flag potentially fraudulent transactions.\n",
        "\n",
        "## Team Details\n",
        "**Team Name:** TrustShieldAI  \n",
        "**Team Members:**  \n",
        "- Adaeze Ifeanyi – Team Lead  \n",
        "- Abdusshakur Abdurrahman – Team Member  \n",
        "\n",
        "This project demonstrates a combination of data simulation, feature engineering, exploratory analysis, and advanced anomaly detection techniques for real-time fraud detection systems.\n"
      ],
      "metadata": {
        "id": "ns_MUwoeaSqo"
      },
      "id": "ns_MUwoeaSqo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fraud Dataset Generation and Transaction Simulation\n",
        "\n",
        "Simulate realistic financial transactions with both normal and fraudulent activity:\n",
        "- Define users, POS and mobile money agents, transaction volume, and geographic locations\n",
        "- Assign transaction channels and agent mappings for realistic workflow\n",
        "- Generate IP addresses by state and create unique device fingerprints\n",
        "- Simulate nearby transaction locations and classify time-of-day\n",
        "- Create standard transactions capturing distance from home, agent info, IP, and timestamps\n",
        "\n",
        "Fraud scenarios simulated:\n",
        "- Velocity/Burst Fraud → multiple rapid transactions in short intervals\n",
        "- Cross-State POS-Card Fraud → transaction occurs in a different state from user’s home\n",
        "- Same-State POS-Card Fraud → transaction occurs within the same state but at a distant agent\n",
        "\n",
        "What We did:\n",
        "- Configured the simulation environment with reproducible random seeds\n",
        "- Generated realistic Nigerian state coordinates and mapped transaction channels\n",
        "- Implemented helper functions for IP, device ID, nearby location, and time-of-day features\n",
        "- Created functions to simulate standard transactions and various fraud patterns\n",
        "- Built a dataset suitable for training and evaluating fraud detection models\n"
      ],
      "metadata": {
        "id": "vkapAEEJkXmR"
      },
      "id": "vkapAEEJkXmR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a76e947-0a95-4291-a5c8-adb9a6a955cb",
      "metadata": {
        "id": "1a76e947-0a95-4291-a5c8-adb9a6a955cb"
      },
      "outputs": [],
      "source": [
        "#importing required libraries\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from geopy.distance import geodesic\n",
        "import math\n",
        "import csv\n",
        "import uuid\n",
        "import hashlib\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Config\n",
        "n_users = 8000\n",
        "n_pos_agents = 200  # POS agents\n",
        "n_momo_agents = 100  # Mobile money agents\n",
        "n_transactions = 50000\n",
        "print(\"Building a real time fraud detector dataset....\")"
      ],
      "metadata": {
        "id": "hf_y7n1RYHWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f90094bc-7bc3-48c5-857f-ad8457704d13"
      },
      "id": "hf_y7n1RYHWp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building a real time fraud detector dataset....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e6c9518-3ed2-4235-97d1-52445946e504",
      "metadata": {
        "id": "6e6c9518-3ed2-4235-97d1-52445946e504",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8851d6b9-bcd7-48ef-fafa-5d1e065aa56a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "States, states coordinates, channels, and transaction types initialized....\n"
          ]
        }
      ],
      "source": [
        "states = [\"Lagos\",\"Ogun\",\"Oyo\",\"Osun\",\"Ondo\",\"Ekiti\",\"Anambra\",\"Enugu\",\"Imo\",\"Abia\",\n",
        "          \"Ebonyi\",\"Rivers\",\"Delta\",\"Edo\",\"Cross River\",\"Akwa Ibom\",\"Bayelsa\",\n",
        "          \"Abuja\",\"Niger\",\"Kwara\",\"Kogi\",\"Benue\",\"Plateau\",\"Nasarawa\",\"Kano\",\n",
        "          \"Kaduna\",\"Katsina\",\"Sokoto\",\"Zamfara\",\"Kebbi\",\"Jigawa\",\"Borno\",\n",
        "          \"Adamawa\",\"Yobe\",\"Bauchi\",\"Gombe\",\"Taraba\"]\n",
        "\n",
        "# Complete realistic coordinates for all 36 Nigerian states\n",
        "state_coords = {\n",
        "    # South West\n",
        "    \"Lagos\": (6.5244, 3.3792),\n",
        "    \"Oyo\": (7.8429, 3.9470),\n",
        "    \"Ogun\": (7.1608, 3.3476),\n",
        "    \"Osun\": (7.5629, 4.5200),\n",
        "    \"Ondo\": (7.2500, 5.2061),\n",
        "    \"Ekiti\": (7.7190, 5.3111),\n",
        "\n",
        "    # South East\n",
        "    \"Anambra\": (6.2209, 6.9982),\n",
        "    \"Enugu\": (6.5244, 7.5106),\n",
        "    \"Imo\": (5.4925, 7.0349),\n",
        "    \"Abia\": (5.4527, 7.5248),\n",
        "    \"Ebonyi\": (6.2649, 8.0137),\n",
        "\n",
        "    # South South\n",
        "    \"Rivers\": (4.8156, 6.9994),\n",
        "    \"Delta\": (5.8921, 5.6805),\n",
        "    \"Edo\": (6.3350, 5.6037),\n",
        "    \"Cross River\": (5.9631, 8.5450),\n",
        "    \"Akwa Ibom\": (5.0077, 7.8536),\n",
        "    \"Bayelsa\": (4.7719, 6.0699),\n",
        "\n",
        "    # North Central\n",
        "    \"Abuja\": (9.0579, 7.4951),\n",
        "    \"Niger\": (10.4806, 6.5432),\n",
        "    \"Kwara\": (8.9670, 4.5993),\n",
        "    \"Kogi\": (7.7323, 6.7411),\n",
        "    \"Benue\": (7.1906, 8.7501),\n",
        "    \"Plateau\": (9.2182, 9.5179),\n",
        "    \"Nasarawa\": (8.5378, 8.5167),\n",
        "\n",
        "    # North West\n",
        "    \"Kano\": (12.0022, 8.5920),\n",
        "    \"Kaduna\": (10.5105, 7.4165),\n",
        "    \"Katsina\": (12.9908, 7.6006),\n",
        "    \"Sokoto\": (13.0059, 5.2476),\n",
        "    \"Zamfara\": (12.1666, 6.6666),\n",
        "    \"Kebbi\": (12.4500, 4.2000),\n",
        "    \"Jigawa\": (12.2300, 9.5500),\n",
        "\n",
        "    # North East\n",
        "    \"Borno\": (11.8846, 13.1571),\n",
        "    \"Adamawa\": (9.3265, 12.3984),\n",
        "    \"Yobe\": (12.2939, 11.9668),\n",
        "    \"Bauchi\": (10.3158, 9.8442),\n",
        "    \"Gombe\": (10.2897, 11.1689),\n",
        "    \"Taraba\": (8.8921, 11.3733)\n",
        "}\n",
        "\n",
        "# Define channels and transaction types\n",
        "channels = [\"POS\", \"MoMo\"]\n",
        "\n",
        "# Transaction types available for each channel\n",
        "transaction_types = {\n",
        "    \"POS\": [\"Card\", \"Transfer\"],\n",
        "    \"MoMo\": [\"Transfer\"]\n",
        "}\n",
        "\n",
        "# Agent allowed transaction types\n",
        "agent= {\n",
        "    \"POS_AGENT\": [\"Card\", \"Transfer\"],\n",
        "    \"MOMO_AGENT\": [\"Transfer\"]\n",
        "}\n",
        "\n",
        "print(\"States, states coordinates, channels, and transaction types initialized....\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bb3fe8d-bbf1-416c-853b-db4e0ade4f9b",
      "metadata": {
        "id": "8bb3fe8d-bbf1-416c-853b-db4e0ade4f9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33787dc7-39e4-40dc-b135-bf500ac5a8df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IP generation by state and region....\n"
          ]
        }
      ],
      "source": [
        "# Enhanced IP generation by state/region\n",
        "def generate_ip_by_state(state):\n",
        "    \"\"\"Generate realistic IP ranges for Nigerian states based on major ISPs\"\"\"\n",
        "    # Nigerian ISP IP ranges by region\n",
        "    state_ip_ranges = {\n",
        "        # South West\n",
        "        \"Lagos\": [(41, 203), (197, 210), (102, 88)],\n",
        "        \"Oyo\": [(41, 204), (154, 115), (102, 89)],\n",
        "        \"Ogun\": [(41, 205), (197, 211), (105, 112)],\n",
        "        \"Osun\": [(41, 206), (154, 116), (102, 90)],\n",
        "        \"Ondo\": [(41, 207), (197, 212), (105, 113)],\n",
        "        \"Ekiti\": [(41, 208), (154, 117), (102, 91)],\n",
        "\n",
        "        # South East\n",
        "        \"Anambra\": [(41, 209), (197, 213), (102, 92)],\n",
        "        \"Enugu\": [(41, 210), (154, 118), (105, 114)],\n",
        "        \"Imo\": [(41, 211), (197, 214), (102, 93)],\n",
        "        \"Abia\": [(41, 212), (154, 119), (105, 115)],\n",
        "        \"Ebonyi\": [(41, 213), (197, 215), (102, 94)],\n",
        "\n",
        "        # South South\n",
        "        \"Rivers\": [(41, 214), (154, 120), (105, 116)],\n",
        "        \"Delta\": [(41, 215), (197, 216), (102, 95)],\n",
        "        \"Edo\": [(41, 216), (154, 121), (105, 117)],\n",
        "        \"Cross River\": [(41, 217), (197, 217), (102, 96)],\n",
        "        \"Akwa Ibom\": [(41, 218), (154, 122), (105, 118)],\n",
        "        \"Bayelsa\": [(41, 219), (197, 218), (102, 97)],\n",
        "\n",
        "        # North Central\n",
        "        \"Abuja\": [(41, 220), (154, 123), (102, 98)],\n",
        "        \"Niger\": [(41, 221), (197, 219), (105, 119)],\n",
        "        \"Kwara\": [(41, 222), (154, 124), (102, 99)],\n",
        "        \"Kogi\": [(41, 223), (197, 220), (105, 120)],\n",
        "        \"Benue\": [(41, 224), (154, 125), (102, 100)],\n",
        "        \"Plateau\": [(41, 225), (197, 221), (105, 121)],\n",
        "        \"Nasarawa\": [(41, 226), (154, 126), (102, 101)],\n",
        "\n",
        "        # North West\n",
        "        \"Kano\": [(154, 113), (41, 227), (105, 122)],\n",
        "        \"Kaduna\": [(154, 114), (41, 228), (197, 222)],\n",
        "        \"Katsina\": [(154, 127), (41, 229), (105, 123)],\n",
        "        \"Sokoto\": [(154, 128), (197, 223), (102, 102)],\n",
        "        \"Zamfara\": [(154, 129), (41, 230), (105, 124)],\n",
        "        \"Kebbi\": [(154, 130), (197, 224), (102, 103)],\n",
        "        \"Jigawa\": [(154, 131), (41, 231), (105, 125)],\n",
        "\n",
        "        # North East\n",
        "        \"Borno\": [(154, 132), (41, 232), (197, 225)],\n",
        "        \"Adamawa\": [(154, 133), (197, 226), (105, 126)],\n",
        "        \"Yobe\": [(154, 134), (41, 233), (102, 104)],\n",
        "        \"Bauchi\": [(154, 135), (197, 227), (105, 127)],\n",
        "        \"Gombe\": [(154, 136), (41, 234), (102, 105)],\n",
        "        \"Taraba\": [(154, 137), (197, 228), (105, 128)]\n",
        "    }\n",
        "\n",
        "    if state in state_ip_ranges:\n",
        "        range_choice = random.choice(state_ip_ranges[state])\n",
        "    else:\n",
        "        # Fallback for any missing states\n",
        "        range_choice = (random.choice([41, 154, 197, 102, 105]), random.randint(200, 240))\n",
        "    return f\"{range_choice[0]}.{range_choice[1]}.{random.randint(0,255)}.{random.randint(1,254)}\"\n",
        "\n",
        "print(\"IP generation by state and region....\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1013beb-16e1-4b19-9f72-1b117ad0784f",
      "metadata": {
        "id": "b1013beb-16e1-4b19-9f72-1b117ad0784f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92115afc-988d-4ae6-d61c-73b1ae50532a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generate_device_id(): creating a random unique device fingerprint...\n",
            "Generate_nearby_location(): generating a realistic nearby latitude/longitude...\n",
            "Get_time_of_day_category(): classifying hour into day, evening, or night...\n"
          ]
        }
      ],
      "source": [
        "def generate_device_id():\n",
        "    return hashlib.md5(str(uuid.uuid4()).encode()).hexdigest()[:16]\n",
        "print(\"Generate_device_id(): creating a random unique device fingerprint...\")\n",
        "\n",
        "def generate_nearby_location(lat, lon, max_distance_km):\n",
        "    angle = random.uniform(0, 2*math.pi)\n",
        "    distance = random.uniform(0, max_distance_km)\n",
        "    lat_offset = (distance * math.cos(angle)) / 111\n",
        "    lon_offset = (distance * math.sin(angle)) / (111 * math.cos(math.radians(lat)))\n",
        "    return lat + lat_offset, lon + lon_offset\n",
        "print(\"Generate_nearby_location(): generating a realistic nearby latitude/longitude...\")\n",
        "\n",
        "def get_time_of_day_category(hour):\n",
        "    if 6 <= hour <= 18:\n",
        "        return \"day\"\n",
        "    elif 19 <= hour <= 22:\n",
        "        return \"evening\"\n",
        "    else:\n",
        "        return \"night\"\n",
        "print(\"Get_time_of_day_category(): classifying hour into day, evening, or night...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7b12131-5d13-403c-8249-148081764db5",
      "metadata": {
        "id": "a7b12131-5d13-403c-8249-148081764db5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81a01668-8175-4e9a-b981-fbee82a46be7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting appropriate agent....\n"
          ]
        }
      ],
      "source": [
        "def select_agent(channel_main, transaction_type, all_agents, target_state=None):\n",
        "    \"\"\"\n",
        "    Select an appropriate agent based on:\n",
        "    - channel_main (POS or MoMo)\n",
        "    - transaction_type (Card or Transfer)\n",
        "    \"\"\"\n",
        "    # Filter by agent type (POS_AGENT or MOMO_AGENT)\n",
        "    if channels == \"POS\":\n",
        "        available_agents = [aid for aid, agent in all_agents.items()\n",
        "                            if agent['type'] == 'POS_AGENT' and transaction_type in agent['transaction_types']]\n",
        "    elif channels == \"MoMo\":\n",
        "        available_agents = [aid for aid, agent in all_agents.items()\n",
        "                            if agent['type'] == 'MOMO_AGENT' and transaction_type in agent['transaction_types']]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "print(\"Selecting appropriate agent....\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f01b281-e206-4719-abd2-3cb07bbcfe39",
      "metadata": {
        "id": "2f01b281-e206-4719-abd2-3cb07bbcfe39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "767684ca-178b-44e0-80a1-61a57b19a9da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating transaction....\n"
          ]
        }
      ],
      "source": [
        "def create_transaction(txn_id, user_id, user, amount, channel, lat, lon,\n",
        "                      transaction_state, ip_address, agent_id, all_agents, timestamp):\n",
        "    \"\"\"Create a transaction record with all required fields\"\"\"\n",
        "    home_location = (user['lat'], user['lon'])\n",
        "    txn_location = (lat, lon)\n",
        "    distance_from_home = geodesic(home_location, txn_location).kilometers\n",
        "\n",
        "    return {\n",
        "        \"transaction_id\": txn_id,\n",
        "        \"user_id\": user_id,\n",
        "        \"amount\": round(amount, 2),\n",
        "        \"channel\": channel,\n",
        "        \"lat\": round(lat, 6),\n",
        "        \"lon\": round(lon, 6),\n",
        "        \"user_home_state\": user['state'],\n",
        "        \"transaction_state\": transaction_state,\n",
        "        \"distance_from_home_km\": round(distance_from_home, 2),\n",
        "        \"ip_address\": ip_address,\n",
        "        \"user_home_ip\": user['home_ip'],\n",
        "        \"agent_id\": agent_id,\n",
        "        \"agent_type\": all_agents[agent_id]['type'] if agent_id else None,\n",
        "        \"timestamp\": timestamp.isoformat(),\n",
        "        \"time_of_day\": get_time_of_day_category(timestamp.hour)\n",
        "    }\n",
        "print(\"Creating transaction....\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9c4135e-4927-4b05-9f3b-f6708f3cb315",
      "metadata": {
        "id": "e9c4135e-4927-4b05-9f3b-f6708f3cb315",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6914fb81-a876-4f85-9b85-8f9120a19ee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating velocity/burst transactions....\n"
          ]
        }
      ],
      "source": [
        "def generate_burst_fraud(txn_id, user_id, user, channel, base_amount, timestamp, all_agents):\n",
        "    \"\"\"Generate velocity/burst attack fraud pattern\"\"\"\n",
        "    transactions = []\n",
        "    burst_size = random.randint(4, 12)\n",
        "    burst_interval = random.randint(1, 5)\n",
        "\n",
        "    # Select initial agent\n",
        "    agent_id = select_agent(channels,transaction_type, all_agents)\n",
        "    if agent_id:\n",
        "        all_agents[agent_id]['suspicious_activity'] = True\n",
        "\n",
        "    for b in range(burst_size):\n",
        "        burst_time = timestamp + timedelta(minutes=b * burst_interval)\n",
        "        amt = base_amount * random.uniform(0.8, 1.3)\n",
        "\n",
        "        # 30% chance of cross-state fraud within burst\n",
        "        if random.random() < 0.3:\n",
        "            fraud_state = random.choice([s for s in states if s != user['state']])\n",
        "            fraud_agent_id = select_agent(channels,transaction_type, all_agents, fraud_state)\n",
        "\n",
        "            if fraud_agent_id:\n",
        "                lat, lon = all_agents[fraud_agent_id]['lat'], all_agents[fraud_agent_id]['lon']\n",
        "                current_agent_id = fraud_agent_id\n",
        "\n",
        "            else:\n",
        "                lat, lon = generate_nearby_location(*state_coords[fraud_state], 10)\n",
        "                current_agent_id = agent_id\n",
        "\n",
        "            transaction_state = fraud_state\n",
        "            ip_address = generate_ip_by_state(fraud_state)\n",
        "        else:\n",
        "            lat, lon = generate_nearby_location(user['lat'], user['lon'], 3)\n",
        "            transaction_state = user['state']\n",
        "            current_agent_id = agent_id\n",
        "            ip_address = user['home_ip'] if random.random() < 0.7 else generate_ip_by_state(user['state'])\n",
        "\n",
        "        transaction = create_transaction(\n",
        "            f\"TXN{txn_id:08d}_{b}\", user_id, user, amt, channel,\n",
        "            lat, lon, transaction_state, ip_address, current_agent_id, all_agents, burst_time\n",
        "        )\n",
        "        transactions.append(transaction)\n",
        "\n",
        "    return transactions\n",
        "print(\"Generating velocity/burst transactions....\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa57af94-4188-4fac-b198-f2920f8a5ab7",
      "metadata": {
        "id": "fa57af94-4188-4fac-b198-f2920f8a5ab7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f52dac94-0df2-4358-e62d-d05a20fd9178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating cross state fraud....\n"
          ]
        }
      ],
      "source": [
        "def generate_cross_state_fraud(txn_id, user_id, user, base_amount, timestamp, all_agents):\n",
        "    \"\"\"\n",
        "    Generate cross-state POS-Card fraud:\n",
        "    - User stays in their home state\n",
        "    - Transaction is recorded through an agent in another state\n",
        "    \"\"\"\n",
        "    user_state = user['state']\n",
        "\n",
        "    # Pick a fraud state different from the user's\n",
        "    fraud_state = random.choice([s for s in states if s != user_state])\n",
        "\n",
        "    # Agent belongs to fraud state\n",
        "    fraud_agent_id = select_agent(\"POS\", \"Card\", all_agents, fraud_state)\n",
        "\n",
        "    if fraud_agent_id:\n",
        "        fraud_lat, fraud_lon = all_agents[fraud_agent_id]['lat'], all_agents[fraud_agent_id]['lon']\n",
        "    else:\n",
        "        fraud_lat, fraud_lon = generate_nearby_location(*state_coords[fraud_state], 15)\n",
        "        fraud_agent_id = None\n",
        "\n",
        "    # Amount unusually high for fraud\n",
        "    amount = base_amount * random.uniform(1.5, 3.0)\n",
        "\n",
        "    # Fraudulent IP matches fraud state\n",
        "    ip_address = generate_ip_by_state(fraud_state)\n",
        "\n",
        "    # Transaction recorded in fraud state, but tied to user’s home state\n",
        "    return create_transaction(\n",
        "        f\"TXN{txn_id:08d}\", user_id, user, amount, \"Card\",\n",
        "        fraud_lat, fraud_lon, fraud_state, ip_address, fraud_agent_id, all_agents, timestamp\n",
        "    )\n",
        "print(\"Generating cross state fraud....\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "145da4e2-ec41-4ef0-9b33-04c432905c57",
      "metadata": {
        "id": "145da4e2-ec41-4ef0-9b33-04c432905c57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce553bde-fd67-40fc-f097-9cfb79911ce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating same state fraud....\n"
          ]
        }
      ],
      "source": [
        "def generate_same_state_pos_fraud(txn_id, user_id, user, base_amount, timestamp, all_agents):\n",
        "    \"\"\"\n",
        "    Generate POS-Card fraud in the SAME state:\n",
        "    - User is at home\n",
        "    - Transaction happens in the same state but at a distant agent location\n",
        "    \"\"\"\n",
        "    user_state = user['state']\n",
        "\n",
        "    # Select an agent in the same state, but not the user's home location\n",
        "    fraud_agent = random.choice([{\"agent_id\": agent_id, **agent_info}\n",
        "        for agent_id, agent_info in all_agents.items()\n",
        "        if agent_info['state'] == user_state\n",
        "    ])\n",
        "\n",
        "    fraud_agent_id = fraud_agent['agent_id']\n",
        "    fraud_lat, fraud_lon = fraud_agent['lat'], fraud_agent['lon']\n",
        "\n",
        "    # Fraud usually involves higher than normal amounts\n",
        "    amount = base_amount * random.uniform(1.5, 3.0)\n",
        "\n",
        "    # IP still resolves to same state\n",
        "    ip_address = generate_ip_by_state(user_state)\n",
        "\n",
        "    # Transaction logged as same-state, but far from user’s true home\n",
        "    return create_transaction(\n",
        "        f\"TXN{txn_id:08d}\", user_id, user, amount, \"Card\",\n",
        "        fraud_lat, fraud_lon, user_state, ip_address, fraud_agent_id, all_agents, timestamp\n",
        "    )\n",
        "print(\"Generating same state fraud....\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dced434-8ca6-4b1d-8266-41be712507cd",
      "metadata": {
        "id": "6dced434-8ca6-4b1d-8266-41be712507cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2899ecb8-d0a5-4247-cf49-ceb766be809d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating normal cross state transaction....\n"
          ]
        }
      ],
      "source": [
        "def generate_normal_cross_state(txn_id, user_id, user, base_amount, timestamp, all_agents):\n",
        "    \"\"\"\n",
        "    Generate a normal cross-state transaction (not fraud, just unusual but valid).\n",
        "    Only for POS Transfer and Mobile Money.\n",
        "    \"\"\"\n",
        "    # Limit channel to only POS Transfer or Mobile Money\n",
        "    channel = random.choice([\"POS Transfer\", \"Mobile Money\"])\n",
        "\n",
        "    # Pick an agent in a different state than the user\n",
        "    user_state = user['state']\n",
        "    agent = random.choice([{\"agent_id\": agent_id, **agent_info}\n",
        "        for agent_id, agent_info in all_agents.items()\n",
        "        if agent_info['state'] != user_state\n",
        "    ])\n",
        "\n",
        "\n",
        "    # Cross-state but valid\n",
        "    transaction_state = agent['state']\n",
        "    lat, lon = agent['lat'], agent['lon']\n",
        "    ip_address = f\"192.168.{random.randint(0,255)}.{random.randint(0,255)}\"\n",
        "    agent_id = agent['agent_id']\n",
        "\n",
        "    # Build the transaction dictionary (no fraud flag)\n",
        "    transaction = create_transaction(\n",
        "        f\"TXN{txn_id:08d}\", user_id, user, base_amount, channel,\n",
        "        lat, lon, transaction_state, ip_address, agent_id, all_agents, timestamp\n",
        "    )\n",
        "\n",
        "    return transaction\n",
        "print(\"Generating normal cross state transaction....\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dfd6afd-001c-49d0-9fdf-4c2a12813c14",
      "metadata": {
        "id": "1dfd6afd-001c-49d0-9fdf-4c2a12813c14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04c581f5-94f0-453a-f152-20e06657792d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating round amount at odd hours....\n"
          ]
        }
      ],
      "source": [
        "def generate_round_amount_fraud(txn_id, user_id, user, channel, timestamp, all_agents):\n",
        "    \"\"\"Generate round number amount fraud at unusual times\"\"\"\n",
        "    round_amounts = [50000, 100000, 150000, 200000, 250000, 500000, 1000000]\n",
        "    amount = random.choice(round_amounts)\n",
        "\n",
        "    fraud_hour = random.choice([2, 3, 4, 23, 1])\n",
        "    fraud_time = timestamp.replace(hour=fraud_hour)\n",
        "\n",
        "    txn_lat = user['lat'] + random.uniform(-0.1, 0.1)\n",
        "    txn_lon = user['lon'] + random.uniform(-0.1, 0.1)\n",
        "\n",
        "    agent_id = select_agent(channel, all_agents)\n",
        "\n",
        "    return create_transaction(\n",
        "        f\"TXN{txn_id:08d}\", user_id, user, amount, channel,\n",
        "        txn_lat, txn_lon, user['state'], user['home_ip'], agent_id, all_agents, fraud_time\n",
        "    )\n",
        "print(\"Generating round amount at odd hours....\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f789eae-34d4-424e-9194-5bf86400789c",
      "metadata": {
        "id": "5f789eae-34d4-424e-9194-5bf86400789c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d665b6-de3b-4803-ecf0-4d090a04c98e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating unusual time pattern and normal transactions....\n"
          ]
        }
      ],
      "source": [
        "def generate_time_fraud(txn_id, user_id, user, channel, base_amount, timestamp, all_agents):\n",
        "    \"\"\"Generate unusual time pattern fraud\"\"\"\n",
        "    unusual_hour = random.choice([1, 2, 3, 4, 5])\n",
        "    unusual_time = timestamp.replace(hour=unusual_hour)\n",
        "    amount = base_amount * random.uniform(1.2, 2.5)\n",
        "\n",
        "    txn_lat, txn_lon = generate_nearby_location(user['lat'], user['lon'], 5)\n",
        "    agent_id = select_agent(channel, all_agents)\n",
        "\n",
        "    return create_transaction(\n",
        "        f\"TXN{txn_id:08d}\", user_id, user, amount, channel,\n",
        "        txn_lat, txn_lon, user['state'], user['home_ip'], agent_id, all_agents, unusual_time\n",
        "    )\n",
        "\n",
        "def generate_normal_transaction(txn_id, user_id, user, channel, base_amount, timestamp, all_agents):\n",
        "    \"\"\"Generate normal transaction\"\"\"\n",
        "    txn_lat, txn_lon = generate_nearby_location(user['lat'], user['lon'], 5)\n",
        "    agent_id = select_agent(channel, all_agents)\n",
        "\n",
        "    return create_transaction(\n",
        "        f\"TXN{txn_id:08d}\", user_id, user, base_amount, channel,\n",
        "        txn_lat, txn_lon, user['state'], user['home_ip'], agent_id, all_agents, timestamp\n",
        "    )\n",
        "print(\"Generating unusual time pattern and normal transactions....\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42978a2c-f4bb-4126-94d6-42d3f002d458",
      "metadata": {
        "id": "42978a2c-f4bb-4126-94d6-42d3f002d458",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e1a4255-7235-4303-e596-a71e037e55dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating users....\n"
          ]
        }
      ],
      "source": [
        "# Generate Users with behavioral patterns\n",
        "def generate_users():\n",
        "    users = {}\n",
        "    for i in range(n_users):\n",
        "        state = random.choice(states)\n",
        "        lat, lon = generate_nearby_location(*state_coords[state], 30)\n",
        "\n",
        "        peak_hours = random.choice([\"morning\", \"afternoon\", \"evening\"])\n",
        "        risk_profile = random.choice([\"low\", \"medium\", \"high\"])\n",
        "        base_amount = 2000 if risk_profile == \"low\" else 50000 if risk_profile == \"medium\" else 10000\n",
        "\n",
        "        users[f\"USR{i:06d}\"] = {\n",
        "            \"state\": state,\n",
        "            \"lat\": lat,\n",
        "            \"lon\": lon,\n",
        "            \"avg_amount\": np.random.lognormal(np.log(base_amount), 0.5),\n",
        "            \"device_id\": generate_device_id(),\n",
        "            \"preferred_channel\": random.choice(channels),\n",
        "            \"peak_hours\": peak_hours,\n",
        "            \"risk_profile\": risk_profile,\n",
        "            \"transaction_count\": 0,\n",
        "            \"home_ip\": generate_ip_by_state(state)\n",
        "        }\n",
        "    return users\n",
        "print(\"Generating users....\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fa1c0d2-c5c0-4d82-8d4c-fa6052983963",
      "metadata": {
        "id": "6fa1c0d2-c5c0-4d82-8d4c-fa6052983963",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68ac8b04-19c3-4744-b65f-41de12ee7115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating agents....\n"
          ]
        }
      ],
      "source": [
        "def generate_agents():\n",
        "    \"\"\"Generate POS and Mobile Money agents\"\"\"\n",
        "    all_agents = {}\n",
        "\n",
        "    # Generate POS agents\n",
        "    for i in range(n_pos_agents):\n",
        "        agent_state = random.choice(states)\n",
        "        lat, lon = generate_nearby_location(*state_coords[agent_state], 20)\n",
        "\n",
        "        all_agents[f\"POS{i:05d}\"] = {\n",
        "            \"type\": \"POS_AGENT\",\n",
        "            \"state\": agent_state,\n",
        "            \"lat\": lat,\n",
        "            \"lon\": lon,\n",
        "            \"channels\": [\"Card\", \"Transfer\"],\n",
        "        }\n",
        "            # Generate Mobile Money agents\n",
        "    for i in range(n_momo_agents):\n",
        "        agent_state = random.choice(states)\n",
        "        lat, lon = generate_nearby_location(*state_coords[agent_state], 20)\n",
        "\n",
        "        all_agents[f\"MOMO{i:05d}\"] = {\n",
        "            \"type\": \"MOMO_AGENT\",\n",
        "            \"state\": agent_state,\n",
        "            \"lat\": lat,\n",
        "            \"lon\": lon,\n",
        "            \"channels\": [\"MobileMoney\"],\n",
        "        }\n",
        "\n",
        "    return all_agents\n",
        "print(\"Generating agents....\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b8b4fc7-a436-44fe-bf8c-3e11a6c5f2e7",
      "metadata": {
        "id": "1b8b4fc7-a436-44fe-bf8c-3e11a6c5f2e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "eeb079df-5909-4766-f7a6-a355e02be4d7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "select_agent() missing 1 required positional argument: 'all_agents'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3777737880.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Normal transaction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mnormal_transaction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_normal_transaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxn_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_amount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_agents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mtransactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_transaction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-247764525.py\u001b[0m in \u001b[0;36mgenerate_normal_transaction\u001b[0;34m(txn_id, user_id, user, channel, base_amount, timestamp, all_agents)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;34m\"\"\"Generate normal transaction\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtxn_lat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtxn_lon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_nearby_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0magent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_agents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     return create_transaction(\n",
            "\u001b[0;31mTypeError\u001b[0m: select_agent() missing 1 required positional argument: 'all_agents'"
          ]
        }
      ],
      "source": [
        "# Main execution\n",
        "users = generate_users()\n",
        "all_agents = generate_agents()\n",
        "\n",
        "# Enhanced transaction generation using helper functions\n",
        "transactions = []\n",
        "user_last_transaction = defaultdict(lambda: datetime.now() - timedelta(days=30))\n",
        "\n",
        "for txn_id in range(1, n_transactions+1):\n",
        "    user_id = random.choice(list(users.keys()))\n",
        "    user = users[user_id]\n",
        "\n",
        "    # Generate timestamp\n",
        "    base_time = datetime.now() - timedelta(days=random.randint(0,90))\n",
        "    hour = random.randint(8, 18) if random.random() < 0.7 else (\n",
        "        random.randint(19, 23) if random.random() < 0.8 else random.randint(0, 7)\n",
        "    )\n",
        "    timestamp = base_time.replace(hour=hour, minute=random.randint(0,59))\n",
        "\n",
        "    # Basic setup\n",
        "    channel = user['preferred_channel'] if random.random() < 0.7 else random.choice(channels)\n",
        "    base_amount = max(100, np.random.lognormal(np.log(user['avg_amount']), 0.6))\n",
        "\n",
        "    # Generate different fraud patterns using helper functions\n",
        "    if random.random() < 0.06:  # Burst fraud\n",
        "        burst_transactions = generate_burst_fraud(txn_id, user_id, user, channel, base_amount, timestamp, all_agents)\n",
        "        transactions.extend(burst_transactions)\n",
        "        user['transaction_count'] += len(burst_transactions)\n",
        "        user_last_transaction[user_id] = timestamp\n",
        "        continue\n",
        "\n",
        "    elif random.random() < 0.04:  # Cross-state fraud\n",
        "        fraud_transaction = generate_cross_state_fraud(txn_id, user_id, user, base_amount, timestamp, all_agents)\n",
        "        transactions.append(fraud_transaction)\n",
        "        continue\n",
        "\n",
        "    elif random.random() < 0.02:  # Same-state POS fraud (user at home, agent elsewhere in same state)\n",
        "        fraud_transaction = generate_same_state_pos_fraud(txn_id, user_id, user, base_amount, timestamp, all_agents)\n",
        "        transactions.append(fraud_transaction)\n",
        "        continue\n",
        "\n",
        "    elif random.random() < 0.03:  # Rare normal cross-state\n",
        "        normal_cross = generate_normal_cross_state(txn_id, user_id, user, base_amount, timestamp, all_agents)\n",
        "        transactions.append(normal_cross)\n",
        "        continue\n",
        "\n",
        "    elif random.random() < 0.03:  # Round amount fraud\n",
        "        fraud_transaction = generate_round_amount_fraud(txn_id, user_id, user, channel, timestamp, all_agents)\n",
        "        transactions.append(fraud_transaction)\n",
        "        continue\n",
        "\n",
        "    elif random.random() < 0.02:  # Time fraud\n",
        "        fraud_transaction = generate_time_fraud(txn_id, user_id, user, channel, base_amount, timestamp, all_agents)\n",
        "        transactions.append(fraud_transaction)\n",
        "        continue\n",
        "\n",
        "    else:  # Normal transaction\n",
        "        normal_transaction = generate_normal_transaction(txn_id, user_id, user, channel, base_amount, timestamp, all_agents)\n",
        "        transactions.append(normal_transaction)\n",
        "\n",
        "    user['transaction_count'] += 1\n",
        "    user_last_transaction[user_id] = timestamp\n",
        "print(\"Combining all functions and exercuting....\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbbb040e-bad8-4640-a74d-736761b87b0b",
      "metadata": {
        "id": "cbbb040e-bad8-4640-a74d-736761b87b0b"
      },
      "outputs": [],
      "source": [
        "# Save enhanced dataset\n",
        "generated_transaction_data = pd.DataFrame(transactions)\n",
        "generated_transaction_data = generated_transaction_data.sort_values('timestamp')\n",
        "\n",
        "# Add derived features\n",
        "generated_transaction_data['hour'] = pd.to_datetime(generated_transaction_data['timestamp']).dt.hour\n",
        "generated_transaction_data['day_of_week'] = pd.to_datetime(generated_transaction_data['timestamp']).dt.dayofweek\n",
        "\n",
        "\n",
        "# Save to CSV\n",
        "file_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "generated_transaction_data.to_csv(f\"transactions_data{file_timestamp}.csv\", index=False)\n",
        "print(f\"Saved as: transactions_data{file_timestamp}.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Adaezeh/TrustShieldAI/main/transactions_data.csv -O transactions_data.csv"
      ],
      "metadata": {
        "id": "u6CG5sEXQpjV"
      },
      "id": "u6CG5sEXQpjV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploratory Data Analysis: Visualizing Transaction Features\n",
        "\n",
        "\n",
        "Use histograms, count plots, and aggregation to explore numeric and categorical transaction features:\n",
        "- Analyze numeric columns: amount, lat, lon, distance_from_home_km, hour, day_of_week\n",
        "- Visualize distributions to identify patterns, ranges, and potential outliers\n",
        "- Examine categorical columns: channel, user_home_state, transaction_state, agent_type, time_of_day\n",
        "- Generate count plots to understand category frequencies and dataset composition\n",
        "\n",
        "What We did:\n",
        "- Plotted histograms for numeric features to observe distribution and detect anomalies\n",
        "- Created count plots for categorical features to reveal popular channels, state-level activity, and agent types\n",
        "- Identified temporal trends in transactions based on time-of-day and day-of-week\n",
        "- Gained insights into the overall dataset composition, informing feature engineering and fraud detection modeling\n",
        "\n"
      ],
      "metadata": {
        "id": "qqHG3HH_k0cI"
      },
      "id": "qqHG3HH_k0cI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43250ee5",
      "metadata": {
        "id": "43250ee5"
      },
      "outputs": [],
      "source": [
        "transaction_data =pd.read_csv(\"transactions_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c49ec6f5",
      "metadata": {
        "id": "c49ec6f5"
      },
      "outputs": [],
      "source": [
        "transaction_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea87db1-4c65-486b-a37c-406e385f15b6",
      "metadata": {
        "id": "5ea87db1-4c65-486b-a37c-406e385f15b6"
      },
      "outputs": [],
      "source": [
        "print(transaction_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "554d5c8b-5fa2-4a58-83c4-2f485cbdb995",
      "metadata": {
        "id": "554d5c8b-5fa2-4a58-83c4-2f485cbdb995"
      },
      "outputs": [],
      "source": [
        "print(transaction_data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a14de7f2-ca02-483c-837f-987d75b6532d",
      "metadata": {
        "id": "a14de7f2-ca02-483c-837f-987d75b6532d"
      },
      "outputs": [],
      "source": [
        "print(transaction_data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f085875-304e-4988-a89d-4fb02756ced7",
      "metadata": {
        "id": "7f085875-304e-4988-a89d-4fb02756ced7"
      },
      "outputs": [],
      "source": [
        "transaction_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46ff3995-c00c-404f-8936-efb17d18d0e4",
      "metadata": {
        "id": "46ff3995-c00c-404f-8936-efb17d18d0e4"
      },
      "outputs": [],
      "source": [
        "print(transaction_data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ab0e601",
      "metadata": {
        "id": "5ab0e601"
      },
      "outputs": [],
      "source": [
        "numeric_cols = ['amount', 'lat', 'lon', 'distance_from_home_km', 'hour', 'day_of_week']\n",
        "\n",
        "transaction_data[numeric_cols].hist(figsize=(12,10), bins=30)\n",
        "plt.suptitle(\"Distribution of Numeric Features\", fontsize=16)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c331ad0e",
      "metadata": {
        "id": "c331ad0e"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efcbd642",
      "metadata": {
        "id": "efcbd642"
      },
      "outputs": [],
      "source": [
        "categorical_cols = ['channel', 'user_home_state', 'transaction_state', 'agent_type', 'time_of_day']\n",
        "\n",
        "for col in categorical_cols:\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.countplot(x=col, data=transaction_data, order=transaction_data[col].value_counts().index)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.title(f\"Distribution of {col}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fraud Detection with Isolation Forest\n",
        "\n",
        "Use preprocessing, feature engineering, and unsupervised learning to detect anomalous transactions:\n",
        "- Transform numeric features (e.g., log of amount, distance from home, percentiles)\n",
        "- Encode categorical variables (channel, state, agent type, time-of-day)\n",
        "- Engineer datetime features (hour and day-of-week as sine/cosine)\n",
        "- Flag night/weekend transactions and very distant transactions\n",
        "\n",
        "What We did:\n",
        "- Preprocessed the transaction dataset, creating numeric, categorical, and derived features\n",
        "- Scaled features using StandardScaler for model stability\n",
        "- Split the dataset into training and testing sets\n",
        "- Trained an Isolation Forest model to detect anomalies without a fixed contamination rate\n",
        "- Predicted fraud for both train and test sets, generating a confidence score\n",
        "- Merged predictions with original and derived features for flagged transactions\n",
        "- Examined feature statistics to understand distribution of values\n",
        "- Saved the trained model for reuse on new transaction data\n",
        "- Created a helper function to apply the model for real-time detection on new transactions\n",
        "\n"
      ],
      "metadata": {
        "id": "lNmyHTNzoDlf"
      },
      "id": "lNmyHTNzoDlf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4fdf1c3-3c02-4a1b-b0f4-7c3ab1f083a7",
      "metadata": {
        "id": "b4fdf1c3-3c02-4a1b-b0f4-7c3ab1f083a7"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6210d4e-1fbc-4222-ab13-fe88fd4cdda9",
      "metadata": {
        "id": "d6210d4e-1fbc-4222-ab13-fe88fd4cdda9"
      },
      "outputs": [],
      "source": [
        "def preprocess_features(df, label_encoders=None, fit_encoders=True):\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # Datetime features\n",
        "    if 'timestamp' in df_processed.columns:\n",
        "        df_processed['hour_sin'] = np.sin(2 * np.pi * df_processed['hour'] / 24)\n",
        "        df_processed['hour_cos'] = np.cos(2 * np.pi * df_processed['hour'] / 24)\n",
        "        df_processed['day_sin'] = np.sin(2 * np.pi * df_processed['day_of_week'] / 7)\n",
        "        df_processed['day_cos'] = np.cos(2 * np.pi * df_processed['day_of_week'] / 7)\n",
        "\n",
        "    # Additional features\n",
        "    df_processed['amount_log'] = np.log1p(df_processed['amount'])\n",
        "    df_processed['is_same_state'] = (df_processed['user_home_state'] == df_processed['transaction_state']).astype(int)\n",
        "    df_processed['is_home_ip'] = (df_processed['ip_address'] == df_processed['user_home_ip']).astype(int)\n",
        "\n",
        "    # Categorical encoding\n",
        "    categorical_cols = ['channel','user_home_state','transaction_state','agent_type','time_of_day']\n",
        "    if label_encoders is None:\n",
        "        label_encoders = {}\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        if col in df_processed.columns:\n",
        "            if fit_encoders:\n",
        "                label_encoders[col] = LabelEncoder()\n",
        "                df_processed[f'{col}_encoded'] = label_encoders[col].fit_transform(df_processed[col].astype(str))\n",
        "            else:\n",
        "                known_categories = set(label_encoders[col].classes_)\n",
        "                df_processed[col] = df_processed[col].astype(str)\n",
        "                df_processed[col] = df_processed[col].apply(lambda x: x if x in known_categories else 'unknown')\n",
        "                if 'unknown' not in known_categories:\n",
        "                    label_encoders[col].classes_ = np.append(label_encoders[col].classes_, 'unknown')\n",
        "                df_processed[f'{col}_encoded'] = label_encoders[col].transform(df_processed[col])\n",
        "\n",
        "    # Feature columns\n",
        "    feature_cols = [\n",
        "        'amount','amount_log','lat','lon','distance_from_home_km',\n",
        "        'hour','day_of_week','hour_sin','hour_cos','day_sin','day_cos',\n",
        "        'is_same_state','is_home_ip'\n",
        "    ]\n",
        "    for col in categorical_cols:\n",
        "        if f'{col}_encoded' in df_processed.columns:\n",
        "            feature_cols.append(f'{col}_encoded')\n",
        "    return df_processed[feature_cols], label_encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3718b05-e24d-4c3e-9bf6-6bc6af9c533d",
      "metadata": {
        "id": "c3718b05-e24d-4c3e-9bf6-6bc6af9c533d"
      },
      "outputs": [],
      "source": [
        "def train_isolation_forest(X_train, contamination=0.05, max_samples=30000):\n",
        "    iso_forest = IsolationForest(\n",
        "        contamination=contamination,\n",
        "        random_state=42,\n",
        "        n_estimators=100,\n",
        "        max_samples=min(max_samples, len(X_train))\n",
        "    )\n",
        "    iso_forest.fit(X_train)\n",
        "    return iso_forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ce2e72f-f798-4d60-a5ce-d73d2c25baba",
      "metadata": {
        "id": "5ce2e72f-f798-4d60-a5ce-d73d2c25baba"
      },
      "outputs": [],
      "source": [
        "def predict_if_fraud(X_scaled, iso_forest):\n",
        "    if_pred = iso_forest.predict(X_scaled)\n",
        "    if_anomalies = if_pred.astype(int)\n",
        "    results = pd.DataFrame({\n",
        "        'is_fraud': if_anomalies,\n",
        "        'isolation_forest_flagged': if_anomalies\n",
        "    }, index=X_scaled.index)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2edd0bee-e5fb-4697-9005-0819b2caf999",
      "metadata": {
        "id": "2edd0bee-e5fb-4697-9005-0819b2caf999"
      },
      "outputs": [],
      "source": [
        "# Preprocess\n",
        "X, label_encoders = preprocess_features(transaction_data)\n",
        "\n",
        "X.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59f9d1ee",
      "metadata": {
        "id": "59f9d1ee"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_scaled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5aa338f-7b98-4c85-b15b-300fe4c9c167",
      "metadata": {
        "id": "e5aa338f-7b98-4c85-b15b-300fe4c9c167"
      },
      "outputs": [],
      "source": [
        "# Train Isolation Forest\n",
        "iso_forest = train_isolation_forest(X_scaled)\n",
        "\n",
        "# Predict fraud\n",
        "results_if = predict_if_fraud(pd.DataFrame(X_scaled, columns=X.columns), iso_forest)\n",
        "results_if.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "249b56ec-36f6-440f-b685-a24add62f610",
      "metadata": {
        "id": "249b56ec-36f6-440f-b685-a24add62f610"
      },
      "outputs": [],
      "source": [
        "# Add original (unscaled) features back\n",
        "results_with_features = pd.concat([X.reset_index(drop=True), results_if.reset_index(drop=True)], axis=1)\n",
        "\n",
        "results_with_features.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52ae93a0-00c3-4223-ab8c-7db0fc3e2cb1",
      "metadata": {
        "id": "52ae93a0-00c3-4223-ab8c-7db0fc3e2cb1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new\n",
        "print(\"Loading your transaction data...\")\n",
        "print(f\"Dataset loaded: {transaction_data.shape[0]} transactions, {transaction_data.shape[1]} features\")\n",
        "\n",
        "class EnhancedIsolationForestDetector:\n",
        "    \"\"\"\n",
        "    Unsupervised Isolation Forest detector for fraud/outlier detection.\n",
        "    Automatically determines anomalies without a fixed contamination rate.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, max_samples=30000):\n",
        "        self.max_samples = max_samples\n",
        "        self.iso_forest = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_encoders = {}\n",
        "        self.feature_names = []\n",
        "        self.feature_stats = {}\n",
        "\n",
        "    def preprocess_features(self, df, fit_encoders=True):\n",
        "        \"\"\"Preprocess dataset: numeric transformations, datetime features, categorical encoding\"\"\"\n",
        "        df_processed = df.copy()\n",
        "\n",
        "        # Datetime features (your dataset already has hour and day_of_week)\n",
        "        if 'hour' in df_processed.columns:\n",
        "            df_processed['hour_sin'] = np.sin(2 * np.pi * df_processed['hour'] / 24)\n",
        "            df_processed['hour_cos'] = np.cos(2 * np.pi * df_processed['hour'] / 24)\n",
        "        if 'day_of_week' in df_processed.columns:\n",
        "            df_processed['day_sin'] = np.sin(2 * np.pi * df_processed['day_of_week'] / 7)\n",
        "            df_processed['day_cos'] = np.cos(2 * np.pi * df_processed['day_of_week'] / 7)\n",
        "\n",
        "        # Numeric features\n",
        "        df_processed['amount_log'] = np.log1p(df_processed['amount'])\n",
        "        df_processed['is_same_state'] = (df_processed['user_home_state'] == df_processed['transaction_state']).astype(int)\n",
        "        df_processed['is_home_ip'] = (df_processed['ip_address'] == df_processed['user_home_ip']).astype(int)\n",
        "        df_processed['amount_percentile'] = df_processed['amount'].rank(pct=True)\n",
        "        df_processed['is_night_transaction'] = ((df_processed['hour'] >= 22) | (df_processed['hour'] <= 5)).astype(int)\n",
        "        df_processed['is_weekend'] = (df_processed['day_of_week'] >= 5).astype(int)\n",
        "\n",
        "        if 'distance_from_home_km' in df_processed.columns:\n",
        "            df_processed['very_far_from_home'] = (df_processed['distance_from_home_km'] > 500).astype(int)\n",
        "            df_processed['distance_log'] = np.log1p(df_processed['distance_from_home_km'])\n",
        "\n",
        "        # Categorical encoding\n",
        "        categorical_cols = ['channel', 'user_home_state', 'transaction_state', 'agent_type', 'time_of_day']\n",
        "        for col in categorical_cols:\n",
        "            if col in df_processed.columns:\n",
        "                if fit_encoders:\n",
        "                    self.label_encoders[col] = LabelEncoder()\n",
        "                    df_processed[f'{col}_encoded'] = self.label_encoders[col].fit_transform(df_processed[col].astype(str))\n",
        "                else:\n",
        "                    if col in self.label_encoders:\n",
        "                        known_categories = set(self.label_encoders[col].classes_)\n",
        "                        df_processed[col] = df_processed[col].astype(str).apply(lambda x: x if x in known_categories else 'unknown')\n",
        "                        if 'unknown' not in known_categories:\n",
        "                            self.label_encoders[col].classes_ = np.append(self.label_encoders[col].classes_, 'unknown')\n",
        "                        df_processed[f'{col}_encoded'] = self.label_encoders[col].transform(df_processed[col])\n",
        "\n",
        "        # Combine all feature columns\n",
        "        feature_cols = [\n",
        "            'amount','amount_log','amount_percentile',\n",
        "            'lat','lon','distance_from_home_km',\n",
        "            'hour','day_of_week','hour_sin','hour_cos','day_sin','day_cos',\n",
        "            'is_same_state','is_home_ip','is_night_transaction','is_weekend'\n",
        "        ]\n",
        "        if 'very_far_from_home' in df_processed.columns:\n",
        "            feature_cols.extend(['very_far_from_home', 'distance_log'])\n",
        "        for col in categorical_cols:\n",
        "            if f'{col}_encoded' in df_processed.columns:\n",
        "                feature_cols.append(f'{col}_encoded')\n",
        "\n",
        "        available_features = [col for col in feature_cols if col in df_processed.columns]\n",
        "        self.feature_names = available_features\n",
        "\n",
        "        return df_processed[available_features]\n",
        "\n",
        "    def train_isolation_forest(self, X_train):\n",
        "        \"\"\"Train Isolation Forest without fixed contamination\"\"\"\n",
        "        print(f\"Training Isolation Forest with {X_train.shape[0]} samples and {X_train.shape[1]} features...\")\n",
        "        self.iso_forest = IsolationForest(\n",
        "            contamination='auto',  # automatically determines anomaly threshold\n",
        "            random_state=42,\n",
        "            n_estimators=100,\n",
        "            max_samples=min(self.max_samples, len(X_train))\n",
        "        )\n",
        "        self.iso_forest.fit(X_train)\n",
        "\n",
        "        feature_df = pd.DataFrame(X_train, columns=self.feature_names)\n",
        "        self.feature_stats = {\n",
        "            'means': feature_df.mean().to_dict(),\n",
        "            'stds': feature_df.std().to_dict(),\n",
        "            'mins': feature_df.min().to_dict(),\n",
        "            'maxs': feature_df.max().to_dict()\n",
        "        }\n",
        "\n",
        "        print(\"Training complete!\")\n",
        "        return self.iso_forest\n",
        "\n",
        "    def predict_fraud(self, X_scaled, return_scores=False):\n",
        "        \"\"\"Predict anomalies (fraud)\"\"\"\n",
        "        if self.iso_forest is None:\n",
        "            raise ValueError(\"Model not trained yet. Call train_isolation_forest first.\")\n",
        "\n",
        "        if_pred = self.iso_forest.predict(X_scaled)\n",
        "        if_scores = self.iso_forest.decision_function(X_scaled)\n",
        "        if_anomalies = (if_pred == -1).astype(int)\n",
        "\n",
        "        results = pd.DataFrame({\n",
        "            'is_fraud': if_anomalies,\n",
        "            'isolation_forest_flagged': if_anomalies,\n",
        "            'confidence_score': self.normalize_scores(if_scores)\n",
        "        })\n",
        "        if return_scores:\n",
        "            results['raw_anomaly_score'] = if_scores\n",
        "\n",
        "        return results\n",
        "\n",
        "    def normalize_scores(self, scores):\n",
        "        min_score = scores.min()\n",
        "        max_score = scores.max()\n",
        "        if min_score == max_score:\n",
        "            return np.zeros_like(scores)\n",
        "        normalized = (max_score - scores) / (max_score - min_score)\n",
        "        return np.clip(normalized, 0, 1)\n",
        "\n",
        "    def save_model(self, filepath_prefix='isolation_forest_model'):\n",
        "        \"\"\"Save model and preprocessing objects\"\"\"\n",
        "        model_data = {\n",
        "            'iso_forest': self.iso_forest,\n",
        "            'scaler': self.scaler,\n",
        "            'label_encoders': self.label_encoders,\n",
        "            'feature_names': self.feature_names,\n",
        "            'feature_stats': self.feature_stats,\n",
        "            'max_samples': self.max_samples\n",
        "        }\n",
        "        joblib.dump(model_data, f'{filepath_prefix}.pkl')\n",
        "        print(f\"✅ Model saved as {filepath_prefix}.pkl\")\n",
        "\n",
        "    def load_model(self, filepath):\n",
        "        \"\"\"Load previously trained model\"\"\"\n",
        "        model_data = joblib.load(filepath)\n",
        "        self.iso_forest = model_data['iso_forest']\n",
        "        self.scaler = model_data['scaler']\n",
        "        self.label_encoders = model_data['label_encoders']\n",
        "        self.feature_names = model_data['feature_names']\n",
        "        self.feature_stats = model_data['feature_stats']\n",
        "        self.max_samples = model_data['max_samples']\n",
        "        print(f\"✅ Model loaded from {filepath}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "g5dipbQn3eCf"
      },
      "id": "g5dipbQn3eCf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  USAGE WORKFLOW\n",
        "\n",
        "# Step 1: Initialize the detector\n",
        "detector = EnhancedIsolationForestDetector(max_samples=30000)\n",
        "\n",
        "# Step 2: Preprocess the transaction_data (add our CSV here)\n",
        "print(\"\\nPreprocessing features...\")\n",
        "X_features = detector.preprocess_features(transaction_data, fit_encoders=True)\n",
        "print(f\"Features created: {list(X_features.columns)}\")\n",
        "\n",
        "# Step 3: Scale the features\n",
        "print(\"\\nScaling features...\")\n",
        "X_scaled = detector.scaler.fit_transform(X_features)\n",
        "\n",
        "# Step 4: Split data for training/testing (optional - you can train on all data)\n",
        "X_train, X_test = train_test_split(X_scaled, test_size=0.2, random_state=42)\n",
        "train_indices, test_indices = train_test_split(range(len(X_scaled)), test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "\n",
        "# Step 5: Train the model\n",
        "detector.train_isolation_forest(X_train)\n",
        "\n",
        "# Step 6: Make predictions\n",
        "print(\"\\nMaking fraud predictions...\")\n",
        "train_results = detector.predict_fraud(X_train, return_scores=True)\n",
        "test_results = detector.predict_fraud(X_test, return_scores=True)\n",
        "\n",
        "# Step 7: Analyze results\n",
        "print(f\"\\n TRAINING SET RESULTS \")\n",
        "print(f\"Total transactions: {len(train_results)}\")\n",
        "print(f\"Flagged as fraud: {train_results['is_fraud'].sum()}\")\n",
        "print(f\"Fraud rate: {train_results['is_fraud'].mean():.2%}\")\n",
        "\n",
        "print(f\"\\n TEST SET RESULTS \")\n",
        "print(f\"Total transactions: {len(test_results)}\")\n",
        "print(f\"Flagged as fraud: {test_results['is_fraud'].sum()}\")\n",
        "print(f\"Fraud rate: {test_results['is_fraud'].mean():.2%}\")\n",
        "\n",
        "# Step 8: Examine flagged transactions (merged original + derived features)\n",
        "\n",
        "# Get indices of flagged anomalies in the test set\n",
        "flagged_indices = [idx for idx, val in zip(test_indices, test_results['is_fraud'].values) if val == 1]\n",
        "\n",
        "# Extract original transaction data for flagged transactions\n",
        "flagged_transactions = transaction_data.loc[flagged_indices].copy()\n",
        "\n",
        "# Add derived features from processed DataFrame\n",
        "derived_features = ['is_same_state', 'is_home_ip', 'is_night_transaction',\n",
        "                    'is_weekend', 'very_far_from_home', 'distance_log']\n",
        "# Only include features that exist (some may not exist depending on your data)\n",
        "available_derived = [f for f in derived_features if f in X_features.columns]\n",
        "flagged_transactions = pd.concat([flagged_transactions, X_features.loc[flagged_indices, available_derived]], axis=1)\n",
        "\n",
        "# Print a sample of flagged transactions\n",
        "print(f\"\\nSAMPLE FLAGGED TRANSACTIONS\")\n",
        "print(flagged_transactions[['transaction_id', 'user_id', 'amount', 'channel',\n",
        "                            'distance_from_home_km', 'is_same_state', 'time_of_day'] + available_derived].head())\n",
        "\n",
        "\n",
        "# Step 9: Feature importance analysis (manual)\n",
        "print(f\"\\n FEATURE STATISTICS \")\n",
        "for feature, mean_val in detector.feature_stats['means'].items():\n",
        "    print(f\"{feature}: mean={mean_val:.3f}, std={detector.feature_stats['stds'][feature]:.3f}\")\n",
        "\n",
        "# Step 10: Save the model for future use\n",
        "detector.save_model('fraud_detector_model')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9mJ-GJdd3eGd"
      },
      "id": "9mJ-GJdd3eGd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transaction_data.head()"
      ],
      "metadata": {
        "id": "wo0kWWS2-sVt"
      },
      "id": "wo0kWWS2-sVt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transaction_data.columns"
      ],
      "metadata": {
        "id": "riCNIFZ4FtOD"
      },
      "id": "riCNIFZ4FtOD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_fraud_on_new_data(new_transactions_csv):\n",
        "    \"\"\"\n",
        "    Example of how to use the trained model on new transaction data\n",
        "    \"\"\"\n",
        "    # Load new data\n",
        "    new_data = pd.read_csv(\"content/Book1.csv\")\n",
        "\n",
        "    # Load the trained model\n",
        "    new_detector = EnhancedIsolationForestDetector()\n",
        "    new_detector.load_model('fraud_detector_model.pkl')\n",
        "\n",
        "    # Preprocess (fit_encoders=False since we use existing encoders)\n",
        "    X_new = new_detector.preprocess_features(new_data, fit_encoders=False)\n",
        "\n",
        "    # Scale using existing scaler\n",
        "    X_new_scaled = new_detector.scaler.transform(X_new)\n",
        "\n",
        "    # Predict\n",
        "    fraud_results = new_detector.predict_fraud(X_new_scaled, return_scores=True)\n",
        "\n",
        "    # Add results back to original data\n",
        "    new_data_with_predictions = new_data.copy()\n",
        "    new_data_with_predictions['is_fraud'] = fraud_results['is_fraud']\n",
        "    new_data_with_predictions['fraud_confidence'] = fraud_results['confidence_score']\n",
        "\n",
        "    return new_data_with_predictions\n",
        "\n",
        "print(f\"\\n MODEL TRAINING COMPLETE \")\n",
        "print(\"Your transaction_data.csv has been processed and the model is trained!\")\n",
        "print(\"You can now use detect_fraud_on_new_data() function for real-time detection.\")"
      ],
      "metadata": {
        "id": "6elrYrdu3eJS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c8bcd0b-b867-4433-b11e-5036fdb9234f"
      },
      "id": "6elrYrdu3eJS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== MODEL TRAINING COMPLETE ===\n",
            "Your transaction_data.csv has been processed and the model is trained!\n",
            "You can now use detect_fraud_on_new_data() function for real-time detection.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8uBeGX0PFyLW"
      },
      "id": "8uBeGX0PFyLW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment on Streamlit  \n",
        "\n",
        "To make our fraud detection system accessible and interactive, we deployed the trained model on **Streamlit**.  \n",
        "The application allows users to upload new transaction data and receive real-time fraud detection insights.  \n",
        "\n",
        "🔗 **Access the Streamlit App here:** [Streamlit Deployment Link](https://trustshieldai-nuozwqtlqvkgl8xpjmhq5k.streamlit.app/)  \n"
      ],
      "metadata": {
        "id": "VJvXKDiTxrgO"
      },
      "id": "VJvXKDiTxrgO"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_qMQPla9xw9K"
      },
      "id": "_qMQPla9xw9K",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}